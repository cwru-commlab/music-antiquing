{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe71a07-b833-400d-ace0-68bf27b5f85c",
   "metadata": {},
   "source": [
    "# Music  Antiquing, Part 1 â€” ECSE 351, Spring 2025\n",
    "\n",
    "This is the first part of the Music Antiquing exercise. Over the course of the semester, we'll use Python to add effects to a sound clip to make it sound like it's playing on a gramophone. Here's where the goalposts are: https://youtu.be/QbsXLDNPvNc?t=28 \n",
    "\n",
    "Use the code below and a favorite piece of music that has good dynamic range and frequency span.  Make a one-minute monaural sound file from it (e.g., a .wav file).   Filter the music to a gramophone channel (160 Hz to 2000 Hz), to a telephone channel (300-3000 Hz), to an AM broadcast radio channel (200-5000 Hz), and to an FM broadcast radio channel (30-15,000 Hz). \n",
    "Hint: All you need to do is copy the code and change F1 and F2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33bc35-d583-4651-9e36-a7ec502766cb",
   "metadata": {},
   "source": [
    "## ðŸ“¡ Assignment requirements\n",
    " - [X] Open the Jupyter notebook.\n",
    " - [ ] Upload a .wav file of your choice.\n",
    " - [ ] Run the sample code for your .wav file.\n",
    " - [ ] Listen to the recordings. Repeat this process for AM and FM broadcast bands by changing the values for F1 and F2. \n",
    " - [ ] Change the code below to filter the .WAV file to a gramophone frequency range. (Also, you'll want to change the code that generates the filename to read \"gramophone\" instead of \"telephone.\"\n",
    " - [ ] Download and save a local copy of your gramophone recording. You'll need it for the next exercise.\n",
    " - [ ] Upload your \"gramophone\" recording here: https://docs.google.com/forms/d/1ICqKKwbJoknCo_0zhtQuk7iVmR31PHFxYuB6FlPYazU/edit\n",
    " - [ ] Optional: Save a local copy of the Jupyter notebook itself. (In Binder, your changes and created files will not be saved.)\n",
    " - [ ] Under \"File\" hit \"Save and Export Notebook As\" and save your file as a PDF.\n",
    " - [ ] Print the PDF and staple it to HW1.\n",
    " - [ ] On the printed copy, highlight the changes you made to the code.\n",
    " - [ ] Annotate the plots. How did the signal change? Does the bandwidth matter? If the signal is going to be bandlimited, do you prefer extending the bass or the treble? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8089d-a117-4f4e-bce5-10469f5f220b",
   "metadata": {},
   "source": [
    "First, we import necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f671e1-624d-4a9c-b010-93e097d64b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from IPython.display import Audio\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35b31f-58fa-41bc-ab80-97ec66f98c84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb88c2db-f585-474d-b3da-e144084d8dbd",
   "metadata": {},
   "source": [
    "## Play and Plot Original .WAV File\n",
    "### &#x1F4E1; Input your filename and ID here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508ef2a-b92e-41b9-a57a-1b3bb0e9988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"example.wav\"\n",
    "ID = \"KD8OXT\" # Put your Case ID here.\n",
    "name = \"YOURNAMEHERE\"\n",
    "\n",
    "# file = input(\"What is your filename?\")\n",
    "# ID = input(\"What is your Case ID?\")\n",
    "# name = input (\"Type your name here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ecd24-9d8f-413d-8121-98cdd2d3c504",
   "metadata": {},
   "source": [
    "### Option 1: Load a local .WAV file.\n",
    "\n",
    "(Note: For the example here it's necessary to transpose the data with the .T operator in Line 6 of the following cell. That may or may not be necessary for your WAV file - if you get an error one way, try the other.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60ed68-c25e-429a-a585-11ba5042c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file\n",
    "fs, data = wavfile.read(path)\n",
    "data = data[:,1] # Switch from stereo to mono\n",
    "# Create and display the Audio object\n",
    "audio = Audio(data.T, rate=fs) #.\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be65b9e-3563-467d-85c7-472e0e046e23",
   "metadata": {},
   "source": [
    "### Option 2: Load a .WAV file from a URL. \n",
    "Here's Kristina's test signal on WWV. Click this link for details. [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5602094.svg)](https://doi.org/10.5281/zenodo.5602094)\n",
    "\n",
    "The code in the cell below is commented out. To run it: \n",
    " - Put your cursor in the cell\n",
    " - Hit CTRL + A to select all the code in the cell\n",
    " - Hit CTRL + / to uncomment the code\n",
    " - Hit CTRL + ENTER to run the code in the cell\n",
    "\n",
    "You can adapt this code for a URL of your own, if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0491cd0-c93b-4a16-a55a-dca9c051eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://zenodo.org/records/5602094/files/test.wav?download=1\"\n",
    "# response = requests.get(url)\n",
    "# # Check if the request was successful\n",
    "# if response.status_code == 200:\n",
    "#     # Write the content to a temporary file\n",
    "#     with open(\"temp.wav\", \"wb\") as f:\n",
    "#         f.write(response.content)\n",
    "\n",
    "#     # Read the WAV file using scipy\n",
    "#     path = \"temp.wav\"\n",
    "#     fs, data = wavfile.read(path)\n",
    "\n",
    "\n",
    "# Audio(data, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158d8db-0ee8-4440-92d9-31f97b25f9a8",
   "metadata": {},
   "source": [
    "Let's plot the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a90a68-8a11-4a55-9c26-4693d1e0b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(data)\n",
    "plt.title(\"Time Domain Plot by  \" + name)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Spectrogram by  \" + name)\n",
    "plt.specgram(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b62c62-47ee-4131-9b5f-7c58dcdbe7c2",
   "metadata": {},
   "source": [
    "## Apply filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61554451-9df5-4ec9-b45f-84b208f61c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filter parameters\n",
    "\n",
    "# Telephone\n",
    "F1 = 300\n",
    "F2 = 3000\n",
    "\n",
    "# # AM Broadcast\n",
    "# F1 = 200\n",
    "# F2 = 5000\n",
    "\n",
    "# # FM Broadcast\n",
    "# F1 = 30\n",
    "# F2 = 15000\n",
    "\n",
    "# fs = 44100  # Sample rate (adjust if needed)\n",
    "Fn = fs / 2  # Nyquist frequency\n",
    "Wp = [F1/Fn, F2/Fn] \n",
    "\n",
    "# Design Butterworth filter\n",
    "b, a = signal.butter(5, Wp, btype='bandpass')\n",
    "\n",
    "# Apply filter\n",
    "filtered_data = signal.lfilter(b, a, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be53278-c5dd-42f4-856e-4b80a65b9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FFT\n",
    "bfilt = np.fft.fft(data)               # Take FFT of original data\n",
    "afilt = np.fft.fft(filtered_data)      # Take FFT of filtered data\n",
    "\n",
    "# Plot frequency response\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.abs(bfilt[:len(bfilt)//2]))\n",
    "plt.title('Frequency Response of Unfiltered Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.abs(afilt[:len(afilt)//2]))\n",
    "plt.title('Frequency Response of Filtered Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96b195-7e80-46c9-ba1a-a65c7569c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct time-domain signal\n",
    "foo = np.fft.ifft(afilt)\n",
    "# Play sound\n",
    "from IPython.display import Audio\n",
    "Audio(foo, rate = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1125c9-05d8-463a-af21-4324608ec5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data - data.mean()) # Discard DC offset\n",
    "plt.plot(foo)\n",
    "plt.title(\"Original and Filtered Data from \" + name + \": \" + str(F1) + \" to \" + str(F2) + \" Hz Bandpass\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da0f1d-8dec-44cf-a268-a4f7026082b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"telophone_\" + ID + \".wav\", fs, foo.real.astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
