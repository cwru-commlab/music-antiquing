{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe71a07-b833-400d-ace0-68bf27b5f85c",
   "metadata": {},
   "source": [
    "# Music  Antiquing, Part 2 â€” ECSE 351, Spring 2025\n",
    "\n",
    "This is the second part of the Music Antiquing exercise. Over the course of the semester, we'll use Python to add effects to a sound clip to make it sound like it's playing on a gramophone. Here's where the goalposts are: https://youtu.be/QbsXLDNPvNc?t=28 \n",
    "\n",
    "Use the sound you created in Part 1 for this exercise: music or a sound sample of your choice, filtered to a gramophone channel (160 Hz to 2000 Hz).\n",
    "\n",
    "We'll normalize the signal and add Gaussian noise at different levels:  From the channel's peak, add noise 20 dB, 40 dB, and 60 dB down.  Which sounds roughly like the sound of a gramophone recording to you? (If you want to look at this in MATLAB, the function to use is agwn().)\n",
    "\n",
    "Note that we are not bandlimiting or shaping the noise; in a gramophone, noise shaping might take place from the mechanical dynamics of the tone arm diaphragm and the acoustic filtration of the horn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33bc35-d583-4651-9e36-a7ec502766cb",
   "metadata": {},
   "source": [
    "## ðŸ“¡ Assignment requirements\n",
    " - [X] Open the Jupyter notebook.\n",
    " - [ ] Upload your .wav file from the last assignment.\n",
    " - [ ] Listen to the recordings. Repeat this process for AM and FM broadcast bands by changing the values for F1 and F2. \n",
    " - [ ] Change the code below to filter the .WAV file to a gramophone frequency range. (Also, you'll want to change the code that generates the filename to read \"gramophone\" instead of \"telephone.\"\n",
    " - [ ] Download and save a local copy of your gramophone recording. You'll need it for the next exercise.\n",
    " - [ ] Upload your \"gramophone\" recording here: https://docs.google.com/forms/d/1ICqKKwbJoknCo_0zhtQuk7iVmR31PHFxYuB6FlPYazU/edit\n",
    " - [ ] Optional: Save a local copy of the Jupyter notebook itself. (In Binder, your changes and created files will not be saved.)\n",
    " - [ ] Under \"File\" hit \"Save and Export Notebook As\" and save your file as a PDF.\n",
    " - [ ] Print the PDF and staple it to HW1.\n",
    " - [ ] On the printed copy, highlight the changes you made to the code.\n",
    " - [ ] Annotate the plots. How did the signal change? Does the bandwidth matter? If the signal is going to be bandlimited, do you prefer extending the bass or the treble? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8089d-a117-4f4e-bce5-10469f5f220b",
   "metadata": {},
   "source": [
    "First, we import necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f671e1-624d-4a9c-b010-93e097d64b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from IPython.display import Audio\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35b31f-58fa-41bc-ab80-97ec66f98c84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb88c2db-f585-474d-b3da-e144084d8dbd",
   "metadata": {},
   "source": [
    "## Play and Plot Original .WAV File\n",
    "### &#x1F4E1; Input your filename and ID here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508ef2a-b92e-41b9-a57a-1b3bb0e9988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"KD8OXT\" # Put your Case ID here.\n",
    "name = \"YOURNAMEHERE\"\n",
    "path = \"gramophone_\" + ID + \".wav\"\n",
    "\n",
    "# file = input(\"What is your filename?\")\n",
    "# ID = input(\"What is your Case ID?\")\n",
    "# name = input (\"Type your name here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ecd24-9d8f-413d-8121-98cdd2d3c504",
   "metadata": {},
   "source": [
    "### Load a local .WAV file.\n",
    "\n",
    "Working in Google Collab or Binder? You should be able to open the file structure in the left sidebar and drag your file into it to upload.\n",
    "\n",
    "(Note: For the example here it's necessary to transpose the data with the .T operator in Line 6 of the following cell. That may or may not be necessary for your WAV file - if you get an error one way, try the other.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6505d1-91c7-42be-a221-429c851929e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file\n",
    "fs, data = wavfile.read(path)\n",
    "# data = data[:,1] # Switch from stereo to mono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2478fc23-99a7-4c85-99f5-66c8ded267f3",
   "metadata": {},
   "source": [
    "## Normalize signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86f972-be52-441e-ada5-f11d6dd4e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68274e3c-9927-49f0-996f-b99ff9608fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the Audio object\n",
    "audio = Audio(data.T, rate=fs) #.\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158d8db-0ee8-4440-92d9-31f97b25f9a8",
   "metadata": {},
   "source": [
    "Let's plot the data. The signal is normalized now, so note the limits on the Y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a90a68-8a11-4a55-9c26-4693d1e0b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(data)\n",
    "plt.title(\"Time Domain Plot by  \" + name)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Spectrogram by  \" + name)\n",
    "plt.specgram(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c8aef-7ba5-44dd-b1e1-23c2edd7825c",
   "metadata": {},
   "source": [
    "## Add White Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61554451-9df5-4ec9-b45f-84b208f61c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awgn(x, snr, seed=None):\n",
    "    \"\"\"\n",
    "    Add white Gaussian noise to a signal.\n",
    "\n",
    "    Parameters:\n",
    "        x: The input signal.\n",
    "        snr: Signal-to-noise ratio in dB.\n",
    "        seed: Random seed for reproducibility (optional).\n",
    "    \"\"\"\n",
    "\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Calculate signal power\n",
    "    x_power = np.mean(np.abs(x)**2)\n",
    "\n",
    "    # Calculate noise power based on SNR\n",
    "    noise_power = x_power / (10**(snr/10))\n",
    "\n",
    "    # Generate noise\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), x.shape)\n",
    "\n",
    "    # Add noise to signal\n",
    "    y = x + noise\n",
    "\n",
    "    return y\n",
    "\n",
    "    # Create a test signal\n",
    "signal = data\n",
    "signal = data/max(data)\n",
    "\n",
    "# Add AWGN with SNR of 10 dB\n",
    "noisy_signal = awgn(signal, 10)\n",
    "\n",
    "Audio(noisy_signal, rate = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be53278-c5dd-42f4-856e-4b80a65b9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FFT\n",
    "bfilt = np.fft.fft(signal)               # Take FFT of original data\n",
    "afilt = np.fft.fft(noisy_signal)      # Take FFT of filtered data\n",
    "\n",
    "# Plot frequency response\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.abs(bfilt[:len(bfilt)//2]))\n",
    "plt.title('Frequency Response of Gramophone Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.abs(afilt[:len(afilt)//2]))\n",
    "plt.title('Frequency Response of Noisy Gramophone Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1125c9-05d8-463a-af21-4324608ec5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(noisy_signal)\n",
    "# plt.plot(data - data.mean()) # Discard DC offset\n",
    "plt.plot(signal - signal.mean())\n",
    "plt.legend('a', 'b')\n",
    "plt.title(\"Band-Limited and Noisy Signal from \" + name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da0f1d-8dec-44cf-a268-a4f7026082b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"awgn_gramophone_\" + ID + \".wav\", fs, foo.real.astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
